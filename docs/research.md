---
layout: default
title: Research
---

My research interests currently center on fairness, robustness, and capabilities of language and multimodal foundation models. 

I've been fortunate to work with Final Doshi-Velez at the Harvard Data to Actional Knowledge (DtAK) Lab, Cynthia Dwork at the Kempner Institute, and Lionel Levine at the Cornell Long-term AI Safety Research (LAISR) lab. 

### Select Publications
- **Second author. ["Set-Based Prompting: Provably Solving the Language Model Order Dependency Problem"](https://arxiv.org/abs/2406.03919)** (NeurIPS 2024). Tackled order dependency issues in LLMs with a novel set-based prompting approach, improving reliability.
- **First author. ["Order Independence With Finetuning"](https://openreview.net/pdf?id=08E6XX0Yen)** (ICLR Bi-Align workshop 2025). Developed a finetuning method to ensure order-independent outcomes in language models, enhancing their robustness.
- **Joint first author. ["Evolutionary Prompt Optimization Discovers Emergent Multimodal Reasoning Strategies in Vision-Language Models"](https://openreview.net/pdf?id=u8BO0NFF21)** (ICLR Reasoning and Planning workshop 2025). Evolutionary optimization naturally evolves tool-use strategies.
- **First author. ["Diverse Concept Proposals for Concept Bottleneck Models"](https://arxiv.org/pdf/2412.18059)** (ICML HMCaT workshop 2022). Proposed a method to enhance model interpretability and performance through diverse concept generation in concept bottleneck models.

I'm currently interested in inference time scheduling for reasoning models and the tradeoffs between reasoning and multi-agent debate. 

If you're a fan of these topics, let's chat!!