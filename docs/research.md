---
layout: default
title: Research
---

My research interests currently center on the fairness, robustness, and capabilities of language and multimodal foundation models. 

I've been fortunate to work with Final Doshi-Velez at the Harvard Data to Actional Knowledge (DtAK) Lab, Cynthia Dwork at the Kempner Institute, and Lionel Levine at the Cornell Long-term AI Safety Research (LAISR) lab. 

My prior research includes
- **First author. ["Order Independence With Finetuning"](https://openreview.net/pdf?id=08E6XX0Yen)** (ICLR Bi-Align workshop 2025). Developed a finetuning method to ensure order-independent outcomes in language models, enhancing their robustness.
- **Joint first author. ["Evolutionary Prompt Optimization Discovers Emergent Multimodal Reasoning Strategies in Vision-Language Models"](https://openreview.net/pdf?id=u8BO0NFF21)** (ICLR Reasoning and Planning workshop 2025). Co-led research using evolutionary optimization to uncover multimodal reasoning strategies in vision-language models.
- **Second author. ["Set-Based Prompting: Provably Solving the Language Model Order Dependency Problem"](https://arxiv.org/abs/2406.03919)** (NeurIPS 2024). Tackled order dependency issues in LLMs with a novel set-based prompting approach, improving reliability.
- **First author. ["Diverse Concept Proposals for Concept Bottleneck Models"](https://arxiv.org/pdf/2412.18059)** (ICML 2022). Proposed a method to enhance model interpretability through diverse concept generation in concept bottleneck models.
